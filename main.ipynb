{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting note processing pipeline\n",
      "üîß Using model: mistral-small:22b\n",
      "üìÇ Input directory: /home/vikk/Documents/GitHub/College-Notes/Notes\n",
      "üìÇ Output directory: /home/vikk/Documents/GitHub/College-Notes/Structured_Notes\n",
      "\n",
      "üìÅ Processing: Temp notes.md\n",
      "  üîç Found 1 sections\n",
      "  üìù Section 1: ___\n",
      "    ‚öôÔ∏è  Generating metadata...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'body' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 120\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMOC\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m note_path\u001b[38;5;241m.\u001b[39mname:\n\u001b[1;32m    119\u001b[0m         note_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 120\u001b[0m         \u001b[43mprocess_note_with_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnote_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNOTES_ROOT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Create global indices\u001b[39;00m\n\u001b[1;32m    123\u001b[0m create_global_indices(OUTPUT_DIR)\n",
      "Cell \u001b[0;32mIn[1], line 83\u001b[0m, in \u001b[0;36mprocess_note_with_metadata\u001b[0;34m(note_path, output_dir, model, notes_root)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Generate metadata\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ‚öôÔ∏è  Generating metadata...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m metadata \u001b[38;5;241m=\u001b[39m generate_metadata(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbody\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, model)\n\u001b[1;32m     84\u001b[0m concepts \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcepts\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Generate content if needed\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'body' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_metadata(content: str, model: str) -> Dict:\n",
    "    \"\"\"Generate metadata using local LLM\"\"\"\n",
    "    try:\n",
    "        if not content.strip():\n",
    "            return {}\n",
    "            \n",
    "        prompt = f\"\"\"\n",
    "        Analyze this text and extract key concepts following these rules:\n",
    "        1. Identify primary concept (PascalCase)\n",
    "        2. List 2-5 related concepts (PascalCase)\n",
    "        3. Generate 1-3 tags (lowercase-with-dashes)\n",
    "        4. Create a 1-sentence summary\n",
    "        \n",
    "        Text: {content[:2000]}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = ollama.generate(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            format=\"json\",\n",
    "            options={\"temperature\": 0.2}\n",
    "        )\n",
    "        return response.json().get(\"response\", {})\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def generate_ai_content(title: str, concepts: List[str], folder_hierarchy: List[str], model: str) -> str:\n",
    "    \"\"\"Generate content using AI with folder context\"\"\"\n",
    "    try:\n",
    "        context_path = \" > \".join(folder_hierarchy)\n",
    "        prompt = f\"\"\"\n",
    "        Generate comprehensive content for: {title}\n",
    "        Context Hierarchy: {context_path}\n",
    "        Include:\n",
    "        - Core definitions\n",
    "        - Practical applications\n",
    "        - Relationships to parent concepts\n",
    "        - Simple examples\n",
    "        Use academic tone with Markdown sections\n",
    "        \"\"\"\n",
    "        \n",
    "        response = ollama.generate(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            options={\"temperature\": 0.5}\n",
    "        )\n",
    "        return f\"> **AI Generated Content**\\n{response['response']}\"\n",
    "    except:\n",
    "        return \"> **AI Generation Failed** - Content placeholder\"\n",
    "\n",
    "def process_note_with_metadata(note_path: Path, output_dir: Path, model: str, notes_root: Path):\n",
    "    \"\"\"Process notes with proper folder structure preservation\"\"\"\n",
    "    rel_path = note_path.relative_to(notes_root)\n",
    "    print(f\"\\nüìÅ Processing: {rel_path}\")\n",
    "    \n",
    "    with open(note_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    sections = re.split(r'\\n## ', content)\n",
    "    print(f\"  üîç Found {len(sections)} sections\")\n",
    "    \n",
    "    folder_hierarchy = list(rel_path.parent.parts)\n",
    "    note_stem = note_path.stem\n",
    "    output_folder = output_dir.joinpath(*folder_hierarchy, note_stem)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for i, section in enumerate(sections, 1):\n",
    "        if not section.strip():\n",
    "            continue\n",
    "            \n",
    "        lines = section.split('\\n')\n",
    "        original_title = lines[0].strip('#').strip()\n",
    "        body = '\\n'.join(lines[1:])  # Initialize body here\n",
    "        print(f\"  üìù Section {i}: {original_title}\")\n",
    "        \n",
    "        # Generate metadata\n",
    "        print(\"    ‚öôÔ∏è  Generating metadata...\")\n",
    "        metadata = generate_metadata(f\"{original_title}\\n\\n{body}\", model)\n",
    "        concepts = metadata.get('concepts', [])\n",
    "        ai_generated = False\n",
    "        \n",
    "        # Generate content if empty or lacks subsections\n",
    "        if not body.strip() or not re.search(r'^#+ ', body, flags=re.MULTILINE):\n",
    "            print(\"    ü§ñ Generating AI content...\")\n",
    "            body = generate_ai_content(original_title, concepts, folder_hierarchy, model)\n",
    "            ai_generated = True\n",
    "        \n",
    "        # Create sanitized filename\n",
    "        sanitized_name = re.sub(r'[^\\w\\-_]', '', original_title.replace(' ', '-')).lower()\n",
    "        output_path = output_folder / f\"{sanitized_name}.md\"\n",
    "        \n",
    "        # Handle duplicates\n",
    "        counter = 1\n",
    "        while output_path.exists():\n",
    "            output_path = output_folder / f\"{sanitized_name}-{counter}.md\"\n",
    "            counter += 1\n",
    "        \n",
    "        # Create frontmatter\n",
    "        frontmatter = {\n",
    "            'created': datetime.now().isoformat(),\n",
    "            'modified': datetime.now().isoformat(),\n",
    "            'source': f\"[[{note_stem}]]\",\n",
    "            'hierarchy': folder_hierarchy,\n",
    "            'tags': metadata.get('tags', []),\n",
    "            'summary': metadata.get('summary', ''),\n",
    "            'concepts': concepts,\n",
    "            'ai_generated': ai_generated\n",
    "        }\n",
    "        yaml_front = yaml.safe_dump(frontmatter, sort_keys=False, allow_unicode=True)\n",
    "        \n",
    "        # Build note content\n",
    "        note_content = f\"---\\n{yaml_front}\\n---\\n\\n\"\n",
    "        note_content += f\"# {original_title}\\n\\n\"\n",
    "        note_content += f\"## Context Path\\n{' > '.join(folder_hierarchy)}\\n\\n\" if folder_hierarchy else \"\"\n",
    "        note_content += \"## Content\\n\" + body + \"\\n\\n\"\n",
    "        note_content += \"## Related Concepts\\n\" + '\\n'.join(f\"[[{c}]]\" for c in concepts[1:])\n",
    "        \n",
    "        output_path.write_text(note_content, encoding='utf-8')\n",
    "        print(f\"    üíæ Saved to: {output_path.relative_to(output_dir)}\")\n",
    "\n",
    "def create_global_indices(output_dir: Path):\n",
    "    \"\"\"Create hierarchical indices based on folder structure\"\"\"\n",
    "    print(\"\\nüìö Building global indices...\")\n",
    "    index_content = \"# Knowledge Hierarchy Index\\n\\n\"\n",
    "    \n",
    "    # Walk through the output directory\n",
    "    for path in sorted(output_dir.glob(\"**/*.md\")):\n",
    "        if path.name.startswith('_'):\n",
    "            continue\n",
    "            \n",
    "        # Calculate depth based on folder structure\n",
    "        relative_path = path.relative_to(output_dir)\n",
    "        depth = len(relative_path.parent.parts)\n",
    "        indent = \"  \" * depth\n",
    "        \n",
    "        # Get display name\n",
    "        display_name = relative_path.stem.replace('-', ' ')\n",
    "        \n",
    "        # Create hierarchical link\n",
    "        parent_folders = \"/\".join(relative_path.parent.parts)\n",
    "        index_content += f\"{indent}- [[{parent_folders}/{display_name}]]\\n\"\n",
    "    \n",
    "    index_path = output_dir / \"_HIERARCHY.md\"\n",
    "    index_path.write_text(index_content, encoding='utf-8')\n",
    "    print(f\"    üìñ Index created at: {index_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    VAULT_ROOT = Path(\"/home/vikk/Documents/GitHub/College-Notes\")\n",
    "    NOTES_ROOT = VAULT_ROOT / \"Notes\"\n",
    "    OUTPUT_DIR = VAULT_ROOT / \"Structured_Notes\"\n",
    "    MODEL = \"mistral-small:22b\"\n",
    "    \n",
    "    print(\"üöÄ Starting note processing pipeline\")\n",
    "    print(f\"üîß Using model: {MODEL}\")\n",
    "    print(f\"üìÇ Input directory: {NOTES_ROOT}\")\n",
    "    print(f\"üìÇ Output directory: {OUTPUT_DIR}\")\n",
    "    \n",
    "    # Process notes\n",
    "    note_count = 0\n",
    "    for note_path in NOTES_ROOT.glob(\"**/*.md\"):\n",
    "        if \"MOC\" not in note_path.name:\n",
    "            note_count += 1\n",
    "            process_note_with_metadata(note_path, OUTPUT_DIR, MODEL, NOTES_ROOT)\n",
    "    \n",
    "    # Create global indices\n",
    "    create_global_indices(OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Processing complete! Processed {note_count} notes\")\n",
    "    print(f\"üåê Index available at: {OUTPUT_DIR}/_HIERARCHY.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
