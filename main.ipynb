{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (6.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_metadata(content: str, model: str) -> Dict:\n",
    "    \"\"\"Generate rich metadata using local LLM\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Analyze this note content and generate metadata following these rules:\n",
    "    1. Create -3 main tags (lowercase-with-dashes)\n",
    "    2. Identify 2-5 related concepts (PascalCase)\n",
    "    3. Write a 1-sentence summary\n",
    "    4. Suggest 1-3 aliases\n",
    "    5. Find 1-2 categories\n",
    "    \n",
    "    Content: {content[:2000]}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.generate(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        format=\"json\",\n",
    "        options={\"temperature\": 0.2}\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        return response.json().get(\"response\", {})\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def create_frontmatter(metadata: Dict, source_note: str) -> str:\n",
    "    \"\"\"Create YAML frontmatter with validation\"\"\"\n",
    "    frontmatter = {\n",
    "        'created': datetime.now().isoformat(),\n",
    "        'modified': datetime.now().isoformat(),\n",
    "        'source': f\"[[{source_note}]]\",\n",
    "        'tags': metadata.get('tags', []),\n",
    "        'aliases': metadata.get('aliases', []),\n",
    "        'summary': metadata.get('summary', ''),\n",
    "        'category': metadata.get('category', ''),\n",
    "        'links': {\n",
    "            'outgoing': metadata.get('concepts', []),\n",
    "            'backlinks': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return yaml.safe_dump(frontmatter, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "def process_note_with_metadata(note_path: Path, output_dir: Path, model: str):\n",
    "    \"\"\"Process individual notes with full metadata support\"\"\"\n",
    "    with open(note_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    sections = re.split(r'\\n## ', content)\n",
    "    base_name = note_path.stem\n",
    "    rel_path = note_path.relative_to(output_dir.parent / \"Notes\")\n",
    "    \n",
    "    # Generate note-wide metadata\n",
    "    global_metadata = generate_metadata(content, model)\n",
    "    \n",
    "    for i, section in enumerate(sections):\n",
    "        if not section.strip():\n",
    "            continue\n",
    "            \n",
    "        lines = section.split('\\n')\n",
    "        title = lines[0].strip('#').strip()\n",
    "        body = '\\n'.join(lines[1:])\n",
    "        full_content = f\"{title}\\n\\n{body}\"\n",
    "        \n",
    "        # Generate section-specific metadata\n",
    "        section_metadata = generate_metadata(full_content, model)\n",
    "        combined_metadata = {**global_metadata, **section_metadata}\n",
    "        \n",
    "        # Create frontmatter\n",
    "        frontmatter = create_frontmatter(combined_metadata, base_name)\n",
    "        \n",
    "        # Build note content\n",
    "        note_content = f\"---\\n{frontmatter}\\n---\\n\\n\"\n",
    "        note_content += f\"# {title}\\n\\n\"\n",
    "        note_content += \"## Content\\n\" + body + \"\\n\\n\"\n",
    "        note_content += \"## Connections\\n\"\n",
    "        note_content += \"- [[_MOC|Main Map of Content]]\\n\"\n",
    "        note_content += \"- [[_TAGS|Tag Index]]\\n\"\n",
    "        \n",
    "        # Save note\n",
    "        new_name = f\"{base_name} - {title}\" if title else f\"{base_name} - Section {i+1}\"\n",
    "        output_path = output_dir / rel_path.parent / f\"{new_name}.md\"\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        output_path.write_text(note_content, encoding='utf-8')\n",
    "\n",
    "def create_global_indices(output_dir: Path):\n",
    "    \"\"\"Create global metadata indices\"\"\"\n",
    "    # Tag index\n",
    "    tag_index = defaultdict(list)\n",
    "    # MOC index\n",
    "    moc_content = \"# Global Map of Content\\n\\n\"\n",
    "    \n",
    "    for note in output_dir.glob(\"**/*.md\"):\n",
    "        if note.name.startswith('_'):\n",
    "            continue\n",
    "            \n",
    "        with open(note, 'r', encoding='utf-8') as f:\n",
    "            frontmatter = next(yaml.safe_load_all(f))\n",
    "            \n",
    "            # Populate tag index\n",
    "            for tag in frontmatter.get('tags', []):\n",
    "                tag_index[tag].append(note.relative_to(output_dir))\n",
    "            \n",
    "            # Add to MOC\n",
    "            moc_content += f\"- [[{note.relative_to(output_dir)}]]\\n\"\n",
    "    \n",
    "    # Write tag index\n",
    "    tag_path = output_dir / \"_TAGS.md\"\n",
    "    tag_content = \"# Tag Index\\n\\n\"\n",
    "    for tag, notes in tag_index.items():\n",
    "        tag_content += f\"## {tag}\\n\" + '\\n'.join(\n",
    "            f\"- [[{note}]]\" for note in notes\n",
    "        ) + \"\\n\\n\"\n",
    "    tag_path.write_text(tag_content, encoding='utf-8')\n",
    "    \n",
    "    # Write global MOC\n",
    "    moc_path = output_dir / \"_MOC.md\"\n",
    "    moc_path.write_text(moc_content, encoding='utf-8')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    VAULT_ROOT = Path(\"/home/vikk/Documents/GitHub/College-Notes/\")\n",
    "    INPUT_DIR = VAULT_ROOT / \"Notes\"\n",
    "    OUTPUT_DIR = VAULT_ROOT / \"Meta_Notes\"\n",
    "    MODEL = \"mistral-small:22b\"\n",
    "    \n",
    "    # Process notes\n",
    "    for note_path in INPUT_DIR.glob(\"**/*.md\"):\n",
    "        if \"MOC\" not in note_path.name:\n",
    "            process_note_with_metadata(note_path, OUTPUT_DIR, MODEL)\n",
    "    \n",
    "    # Create global indices\n",
    "    create_global_indices(OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"Metadata-enhanced vault created at: {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
