{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22350/1471933346.py:32: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return response.json().get(\"response\", {})\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_metadata(content: str, model: str) -> Dict:\n",
    "    \"\"\"Generate metadata using local LLM\"\"\"\n",
    "    try:\n",
    "        if not content.strip():\n",
    "            return {}\n",
    "            \n",
    "        prompt = f\"\"\"\n",
    "        Analyze this text and extract key concepts following these rules:\n",
    "        1. Identify primary concept (PascalCase)\n",
    "        2. List 2-5 related concepts (PascalCase)\n",
    "        3. Generate 1-3 tags (lowercase-with-dashes)\n",
    "        4. Create a 1-sentence summary\n",
    "        \n",
    "        Text: {content[:2000]}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = ollama.generate(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            format=\"json\",\n",
    "            options={\"temperature\": 0.2}\n",
    "        )\n",
    "        return response.json().get(\"response\", {})\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def generate_ai_content(title: str, concepts: List[str], folder_hierarchy: List[str], model: str) -> str:\n",
    "    \"\"\"Generate content using AI with folder context\"\"\"\n",
    "    try:\n",
    "        context_path = \" > \".join(folder_hierarchy)\n",
    "        prompt = f\"\"\"\n",
    "        Generate comprehensive content for: {title}\n",
    "        Context Hierarchy: {context_path}\n",
    "        Include:\n",
    "        - Core definitions\n",
    "        - Practical applications\n",
    "        - Relationships to parent concepts\n",
    "        - Simple examples\n",
    "        Use academic tone with Markdown sections\n",
    "        \"\"\"\n",
    "        \n",
    "        response = ollama.generate(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            options={\"temperature\": 0.5}\n",
    "        )\n",
    "        return f\"> **AI Generated Content**\\n{response['response']}\"\n",
    "    except:\n",
    "        return \"> **AI Generation Failed** - Content placeholder\"\n",
    "\n",
    "def process_note_with_metadata(note_path: Path, output_dir: Path, model: str, notes_root: Path):\n",
    "    \"\"\"Process notes with proper folder structure preservation\"\"\"\n",
    "    with open(note_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    sections = re.split(r'\\n## ', content)\n",
    "    rel_path = note_path.relative_to(notes_root)\n",
    "    folder_hierarchy = list(rel_path.parent.parts)\n",
    "    note_stem = note_path.stem  # Original note name without extension\n",
    "    \n",
    "    # Create output folder structure: output/parent_folders/note_stem\n",
    "    output_folder = output_dir.joinpath(*folder_hierarchy, note_stem)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for section in sections:\n",
    "        if not section.strip():\n",
    "            continue\n",
    "            \n",
    "        lines = section.split('\\n')\n",
    "        original_title = lines[0].strip('#').strip()\n",
    "        body = '\\n'.join(lines[1:])\n",
    "        \n",
    "        # Generate metadata with folder context\n",
    "        metadata = generate_metadata(f\"{original_title}\\n\\n{body}\", model)\n",
    "        concepts = metadata.get('concepts', [])\n",
    "        ai_generated = False\n",
    "        \n",
    "        # Generate content if empty or lacks subsections\n",
    "        if not body.strip() or not re.search(r'^#+ ', body, flags=re.MULTILINE):\n",
    "            body = generate_ai_content(original_title, concepts, folder_hierarchy, model)\n",
    "            ai_generated = True\n",
    "        \n",
    "        # Create sanitized filename\n",
    "        sanitized_name = re.sub(r'[^\\w\\-_]', '', original_title.replace(' ', '-')).lower()\n",
    "        output_path = output_folder / f\"{sanitized_name}.md\"\n",
    "        \n",
    "        # Handle duplicates\n",
    "        counter = 1\n",
    "        while output_path.exists():\n",
    "            output_path = output_folder / f\"{sanitized_name}-{counter}.md\"\n",
    "            counter += 1\n",
    "        \n",
    "        # Create frontmatter\n",
    "        frontmatter = {\n",
    "            'created': datetime.now().isoformat(),\n",
    "            'modified': datetime.now().isoformat(),\n",
    "            'source': f\"[[{note_stem}]]\",\n",
    "            'hierarchy': folder_hierarchy,\n",
    "            'tags': metadata.get('tags', []),\n",
    "            'summary': metadata.get('summary', ''),\n",
    "            'concepts': concepts,\n",
    "            'ai_generated': ai_generated\n",
    "        }\n",
    "        yaml_front = yaml.safe_dump(frontmatter, sort_keys=False, allow_unicode=True)\n",
    "        \n",
    "        # Build note content\n",
    "        note_content = f\"---\\n{yaml_front}\\n---\\n\\n\"\n",
    "        note_content += f\"# {original_title}\\n\\n\"\n",
    "        note_content += f\"## Context Path\\n{' > '.join(folder_hierarchy)}\\n\\n\" if folder_hierarchy else \"\"\n",
    "        note_content += \"## Content\\n\" + body + \"\\n\\n\"\n",
    "        note_content += \"## Related Concepts\\n\" + '\\n'.join(f\"[[{c}]]\" for c in concepts[1:])\n",
    "        \n",
    "        output_path.write_text(note_content, encoding='utf-8')\n",
    "\n",
    "def create_global_indices(output_dir: Path):\n",
    "    \"\"\"Create hierarchical indices based on folder structure\"\"\"\n",
    "    index_content = \"# Knowledge Hierarchy Index\\n\\n\"\n",
    "    \n",
    "    # Walk through the output directory\n",
    "    for path in sorted(output_dir.glob(\"**/*.md\")):\n",
    "        if path.name.startswith('_'):\n",
    "            continue\n",
    "            \n",
    "        # Calculate depth based on folder structure\n",
    "        relative_path = path.relative_to(output_dir)\n",
    "        depth = len(relative_path.parent.parts)\n",
    "        indent = \"  \" * depth\n",
    "        \n",
    "        # Get display name\n",
    "        display_name = relative_path.stem.replace('-', ' ')\n",
    "        \n",
    "        # Create hierarchical link\n",
    "        parent_folders = \"/\".join(relative_path.parent.parts)\n",
    "        index_content += f\"{indent}- [[{parent_folders}/{display_name}]]\\n\"\n",
    "    \n",
    "    (output_dir / \"_HIERARCHY.md\").write_text(index_content, encoding='utf-8')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    VAULT_ROOT = Path(\"/home/vikk/Documents/GitHub/College-Notes\")\n",
    "    NOTES_ROOT = VAULT_ROOT / \"Notes\"\n",
    "    OUTPUT_DIR = VAULT_ROOT / \"Structured_Notes\"\n",
    "    MODEL = \"mistral-small:22b\"\n",
    "    \n",
    "    # Process notes\n",
    "    for note_path in NOTES_ROOT.glob(\"**/*.md\"):\n",
    "        if \"MOC\" not in note_path.name:\n",
    "            process_note_with_metadata(note_path, OUTPUT_DIR, MODEL, NOTES_ROOT)\n",
    "    \n",
    "    # Create global indices\n",
    "    create_global_indices(OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"Structure-preserved notes created at: {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
